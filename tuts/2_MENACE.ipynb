{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LD5-1Iw8PafI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import NamedTuple\n",
    "from google.colab import output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I04JDLKvQwPo"
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "BOARD_COL = 3\n",
    "BOARD_ROW = 3\n",
    "BOARD_SIZE = BOARD_COL * BOARD_ROW\n",
    "\n",
    "\"\"\"\n",
    "Game board and actions are: {q, w, e, a, s, d, z, x, c}\n",
    "\n",
    "q | w | e\n",
    "--|---|--\n",
    "a | s | d\n",
    "--|---|--\n",
    "z | x | c\n",
    "\"\"\"\n",
    "ACTIONS_KEY_MAP = {'q': 0, 'w': 1, 'e': 2,\n",
    "                   'a': 3, 's': 4, 'd': 5,\n",
    "                   'z': 6, 'x': 7, 'c': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n7lTbDhBy5Of"
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQhLYLOByy-D"
   },
   "source": [
    "#### State Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IFBWExhtRAMR"
   },
   "outputs": [],
   "source": [
    "def print_state(board, clear_output=False):\n",
    "  if clear_output:\n",
    "    output.clear()\n",
    "  for i in range(BOARD_ROW):\n",
    "    print('-------------')\n",
    "    out = '| '\n",
    "    for j in range(BOARD_COL):\n",
    "      if board[i, j] == 1:\n",
    "          token = 'x'\n",
    "      elif board[i, j] == -1:\n",
    "          token = 'o'\n",
    "      else:\n",
    "          token = ' '  # empty position\n",
    "      out += token + ' | '\n",
    "    print(out)\n",
    "  print('-------------')\n",
    "\n",
    "\n",
    "class State:\n",
    "  def __init__(self, symbol):\n",
    "    # the board is represented by an n * n array,\n",
    "    #  1 represents the player who moves first,\n",
    "    # -1 represents another player\n",
    "    #  0 represents an empty position\n",
    "    self.board = np.zeros((BOARD_ROW, BOARD_COL))\n",
    "    self.symbol = symbol\n",
    "    self.winner = 0\n",
    "    self.end = None\n",
    "\n",
    "  @property\n",
    "  def hash_value(self):\n",
    "    hash = 0\n",
    "    for x in np.nditer(self.board):\n",
    "      hash = 3*hash + x + 1   # unique hash\n",
    "    return hash\n",
    "\n",
    "  def next(self, action: str):\n",
    "    id = ACTIONS_KEY_MAP[action]\n",
    "    i, j = id // BOARD_COL, id % BOARD_COL\n",
    "    return self.next_by_pos(i, j)\n",
    "\n",
    "  def next_by_pos(self, i: int, j: int):\n",
    "    assert self.board[i, j] == 0\n",
    "    new_state = State(-self.symbol)      # another player turn\n",
    "    new_state.board = np.copy(self.board)\n",
    "    new_state.board[i, j] = self.symbol  # current player choose to play at (i, j) pos\n",
    "    return new_state\n",
    "\n",
    "  @property\n",
    "  def possible_actions(self):\n",
    "    rev_action_map = {id: key for key, id in ACTIONS_KEY_MAP.items()}\n",
    "    actions = []\n",
    "    for i in range(BOARD_ROW):\n",
    "      for j in range(BOARD_COL):\n",
    "        if self.board[i, j] == 0:\n",
    "          actions.append(rev_action_map[BOARD_COL*i+j])\n",
    "    return actions\n",
    "\n",
    "  def is_end(self):\n",
    "    if self.end is not None:\n",
    "      return self.end\n",
    "\n",
    "    check = []\n",
    "    # check row\n",
    "    for i in range(BOARD_ROW):\n",
    "      check.append(sum(self.board[i, :]))\n",
    "\n",
    "    # check col\n",
    "    for i in range(BOARD_COL):\n",
    "      check.append(sum(self.board[:, i]))\n",
    "\n",
    "    # check diagonal\n",
    "    diagonal = 0; reverse_diagonal = 0\n",
    "    for i in range(BOARD_ROW):\n",
    "      diagonal += self.board[i, i]\n",
    "      reverse_diagonal += self.board[BOARD_ROW-i-1, i]\n",
    "    check.append(diagonal)\n",
    "    check.append(reverse_diagonal)\n",
    "\n",
    "    for x in check:\n",
    "      if x == 3:\n",
    "        self.end = True\n",
    "        self.winner = 1   # player 1 wins\n",
    "        return self.end\n",
    "      elif x == -3:\n",
    "        self.end = True\n",
    "        self.winner = 2   # player 2 wins\n",
    "        return self.end\n",
    "\n",
    "    for x in np.nditer(self.board):\n",
    "      if x == 0:          # play available\n",
    "        self.end = False\n",
    "        return self.end\n",
    "\n",
    "    self.winner = 0       # draw\n",
    "    self.end = True\n",
    "    return self.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihwyqTpPy2H2"
   },
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XJG-IRKIDsz9"
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "  def __init__(self):\n",
    "    self.all_states = self.get_all_states()\n",
    "    self.curr_state = State(symbol=1)\n",
    "\n",
    "  def get_all_states(self):\n",
    "    all_states = {}  # is a dict with key as state_hash_value and value as State object.\n",
    "    def explore_all_substates(state):\n",
    "      for i in range(BOARD_ROW):\n",
    "        for j in range(BOARD_COL):\n",
    "          if state.board[i, j] == 0:\n",
    "            next_state = state.next_by_pos(i, j)\n",
    "            if next_state.hash_value not in all_states:\n",
    "              all_states[next_state.hash_value] = next_state\n",
    "              if not next_state.is_end():\n",
    "                explore_all_substates(next_state)\n",
    "    curr_state = State(symbol=1)\n",
    "    all_states[curr_state.hash_value] = curr_state\n",
    "    explore_all_substates(curr_state)\n",
    "    return all_states\n",
    "\n",
    "  def reset(self):\n",
    "    self.curr_state = State(symbol=1)\n",
    "    return self.curr_state\n",
    "\n",
    "  def step(self, action):\n",
    "    assert action in self.curr_state.possible_actions, f\"Invalid {action} for the current state \\n{self.curr_state.print_state()}\"\n",
    "    next_state_hash = self.curr_state.next(action).hash_value\n",
    "    next_state = self.all_states[next_state_hash]\n",
    "    self.curr_state = next_state\n",
    "    reward = 0\n",
    "    return self.curr_state, reward\n",
    "\n",
    "  def is_end(self):\n",
    "    return self.curr_state.is_end()\n",
    "\n",
    "  @property\n",
    "  def winner(self):\n",
    "    result_id = self.curr_state.winner\n",
    "    result = 'draw'\n",
    "    if result_id == 1:\n",
    "      result = 'player1'\n",
    "    elif result_id == 2:\n",
    "      result = 'player2'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZKfXapCzHNq"
   },
   "source": [
    "#### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pN3u_Ss0lf88"
   },
   "outputs": [],
   "source": [
    "class BasePolicy:\n",
    "  def reset(self):\n",
    "    pass\n",
    "\n",
    "  def update_values(self, *args):\n",
    "    pass\n",
    "\n",
    "  def select_action(self, state):\n",
    "    raise Exception('Not Implemented Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OfddswzCRK8p"
   },
   "outputs": [],
   "source": [
    "class HumanPolicy(BasePolicy):\n",
    "  def __init__(self, symbol):\n",
    "    self.symbol = symbol\n",
    "\n",
    "  def select_action(self, state):\n",
    "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
    "    print_state(state.board, clear_output=True)\n",
    "    key = input(\"Input your position: \")\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kJ_18UpiogzN"
   },
   "outputs": [],
   "source": [
    "class RandomPolicy(BasePolicy):\n",
    "  def __init__(self, symbol):\n",
    "    self.symbol = symbol\n",
    "\n",
    "  def select_action(self, state):\n",
    "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
    "    return np.random.choice(state.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mos8O8H1RFe5"
   },
   "outputs": [],
   "source": [
    "class ActionPlayed(NamedTuple):\n",
    "  hash_value: str\n",
    "  action: str\n",
    "\n",
    "\n",
    "class MenacePolicy(BasePolicy):\n",
    "  def __init__(self, all_states, symbol, tau=5.0):\n",
    "    self.all_states = all_states\n",
    "    self.symbol = symbol\n",
    "    self.tau = tau\n",
    "\n",
    "    # It store the number of stones for each action for each state\n",
    "    self.state_action_value = self.initialize()\n",
    "    # variable to store the history for updating the number of stones     \n",
    "    self.history = []\n",
    "\n",
    "  def initialize(self):\n",
    "    state_action_value = {}\n",
    "    for hash_value, state in self.all_states.items():\n",
    "      # initially all actions have 0 stones\n",
    "      state_action_value[hash_value] = {action: 0 for action in state.possible_actions}\n",
    "    return state_action_value\n",
    "\n",
    "  def reset(self):\n",
    "    for action_value in self.state_action_value.values():\n",
    "      for action in action_value.keys():\n",
    "        action_value[action] = 0\n",
    "\n",
    "  def print_updates(self, reward):\n",
    "    print(f'Player with symbol {self.symbol} updates the following history with {reward} stone')\n",
    "    for item in self.history:\n",
    "      board = np.copy(self.all_states[item.hash_value].board)\n",
    "      id = ACTIONS_KEY_MAP[item.action]\n",
    "      i, j = id//BOARD_COL, id%BOARD_COL\n",
    "      board[i, j] = self.symbol\n",
    "      print_state(board)\n",
    "\n",
    "  def update_values(self, reward, show_update=False):\n",
    "    # reward: if wins receive reward of 1 stone for the chosen action\n",
    "    #         else -1 stone.\n",
    "    # reward is either 1 or -1 depending upon if the player has won or lost the game.\n",
    "\n",
    "    if show_update:\n",
    "      self.print_updates(reward)\n",
    "    for item in self.history:\n",
    "      # your code here\n",
    "      self.state_action_value[item.hash_value][item.action] += reward\n",
    "    \n",
    "    self.history = []\n",
    "  \n",
    "  def select_action(self, state):  # Softmax action probability\n",
    "    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n",
    "    action_value = self.state_action_value[state.hash_value]\n",
    "    max_value = action_value[max(action_value, key=action_value.get)]\n",
    "    exp_values = {action: np.exp((v-max_value) / self.tau) for action, v in action_value.items()}\n",
    "    normalizer = np.sum([v for v in exp_values.values()])\n",
    "    prob = {action: v/normalizer for action, v in exp_values.items()}\n",
    "    action = np.random.choice(list(prob.keys()), p=list(prob.values()))\n",
    "    self.history.append(ActionPlayed(state.hash_value, action))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MvkDRmozqWM"
   },
   "source": [
    "#### Game Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qzO3FQJcCqpJ"
   },
   "outputs": [],
   "source": [
    "class Game:\n",
    "  def __init__(self, env, player1, player2):\n",
    "    self.env = env\n",
    "    self.player1 = player1\n",
    "    self.player2 = player2\n",
    "    self.show_updates = False\n",
    "\n",
    "  def alternate(self):\n",
    "    while True:\n",
    "      yield self.player1\n",
    "      yield self.player2\n",
    "\n",
    "  def train(self, epochs=1_00_000):\n",
    "    game_results = []\n",
    "    player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
    "    for _ in range(epochs):\n",
    "      result = self.play()\n",
    "\n",
    "      # if player1 wins add 1 stone for the action chosen \n",
    "      player1_reward = player1_reward_map[result]\n",
    "      player2_reward = -player1_reward   # if player2 wins add 1 stone\n",
    "\n",
    "      self.player1.update_values(player1_reward)\n",
    "      self.player2.update_values(player2_reward)\n",
    "\n",
    "  def play(self):\n",
    "    alternate = self.alternate()\n",
    "    state = self.env.reset()\n",
    "    while not self.env.is_end():\n",
    "      player = next(alternate)\n",
    "      action = player.select_action(state)\n",
    "      state, _ = self.env.step(action)\n",
    "    result = self.env.winner\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-gqpWkKztLm"
   },
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pr62H-hLLYdt"
   },
   "outputs": [],
   "source": [
    "env = Env()\n",
    "\n",
    "player1 = MenacePolicy(env.all_states, symbol=1)\n",
    "player2 = MenacePolicy(env.all_states, symbol=-1)\n",
    "# player2= RandomPolicy(symbol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O0d23Pz5SR_y"
   },
   "outputs": [],
   "source": [
    "game = Game(env, player1, player2)\n",
    "game.train(epochs=1_00_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYWsTiWaDkyR",
    "outputId": "52cfe5c2-4bef-4ba2-af96-6e63515836e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner: draw\n",
      "Player with symbol 1 updates the following history with 0 stone\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "game.play()\n",
    "result = env.winner\n",
    "print(f\"winner: {result}\")\n",
    "\n",
    "player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
    "player1.update_values(player1_reward_map[result], show_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMbqaln6TDXZ",
    "outputId": "48289780-8930-4c9e-db97-8cb99b7c2742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "Input your position: z\n",
      "winner: draw\n",
      "Player with symbol 1 updates the following history with 0 stone\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "game_with_human_player = Game(env, player1, HumanPolicy(symbol=-1))\n",
    "\n",
    "game_with_human_player.play()\n",
    "result = env.winner\n",
    "print(f\"winner: {result}\")\n",
    "\n",
    "player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n",
    "player1.update_values(player1_reward_map[result], show_update=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
